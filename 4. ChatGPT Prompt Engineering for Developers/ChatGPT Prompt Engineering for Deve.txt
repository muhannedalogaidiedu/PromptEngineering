
# ChatGPT Prompt Engineering for Developers

## What you'll learn

Learn prompt engineering best practices for application development. Discover new ways to use LLMs, including how to build your own custom chatbot. Gain hands-on practice writing and iterating on prompts yourself using the OpenAI API.

## About this course

In ChatGPT Prompt Engineering for Developers, you will learn how to use a large language model (LLM) to quickly build new and powerful applications. Using the OpenAI API, you’ll be able to quickly build capabilities that learn to innovate and create value in ways that were cost-prohibitive, highly technical, or simply impossible before now. This short course taught by Isa Fulford (OpenAI) and Andrew Ng (DeepLearning.AI) will describe how LLMs work, provide best practices for prompt engineering, and show how LLM APIs can be used in applications for a variety of tasks, including summarizing (e.g., summarizing user reviews for brevity), inferring (e.g., sentiment classification, topic extraction), transforming text (e.g., translation, spelling & grammar correction), and expanding (e.g., automatically writing emails). In addition, you’ll learn two key principles for writing effective prompts, how to systematically engineer good prompts, and also learn to build a custom chatbot. All concepts are illustrated with numerous examples, which you can play with directly in our Jupyter notebook environment to get hands-on experience with prompt engineering.

## Introduction

Welcome to this course on ChatGPT Prompt Engineering for Developers. I'm thrilled to have with me Isa Fulford to teach this along with me. She is a member of the technical staff of OpenAI and built the popular ChatGPT Retrieval plugin, and a large part of her work has been teaching people how to use LLM or Large Language Model technology in products. She's also contributed to the OpenAI Cookbook that teaches people prompting. So thrilled to have you with me. And I'm thrilled to be here and share some prompting best practices with you all.

There’s been a lot of material on the internet for prompting with articles like “30 prompts everyone has to know.” A lot of that has been focused on the ChatGPT web user interface, which many people are using to do specific and often one-off tasks. But the power of LLMs as a developer tool—that is, using API calls to LLMs to quickly build software applications—is still very underappreciated. My team at AI Fund, which is a sister company to DeepLearning.ai, has been working with many startups on applying these technologies to different applications, and it's been exciting to see what LLM APIs can enable developers to quickly build.

In this course, we'll share possibilities for what you can do, as well as best practices for how you can do them. There’s a lot of material to cover. First, you'll learn some prompting best practices for software development, then we'll cover some common use cases—summarizing, inferring, transforming, expanding—and then you'll build a chatbot using an LLM. We hope that this will spark your imagination about new applications that you can build.

In the development of large language models or LLMs, there have been broadly two types of LLMs: base LLMs and instruction-tuned LLMs. A base LLM has been trained to predict the next word based on text training data, often trained on a large amount of data from the internet and other sources to figure out what's the next most likely word to follow. For example, if you prompt it with “Once upon a time there was a unicorn,” it may complete this with “that lived in a magical forest with all its unicorn friends.”

But if you were to prompt it with “What is the capital of France,” then based on what articles on the internet might have, it might complete with “What is France's largest city,” or “What is France's population,” and so on, because the base model might associate the question with other quiz questions about France. In contrast, an instruction-tuned LLM has been trained to follow instructions. So if you ask “What is the capital of France,” it’s more likely to answer “The capital of France is Paris.”

Instruction-tuned models start from a base model and are further fine-tuned with input-output pairs of instructions and good responses, then often refined with reinforcement learning from human feedback (RLHF) to make them better at being helpful and following instructions. Because instruction-tuned models are trained to be helpful, honest, and harmless—and are less likely to output problematic text such as toxic content—a lot of practical usage has shifted toward instruction-tuned models. For most practical applications today, we recommend using instruction-tuned LLMs, which are easier to use and safer.

When you use an instruction-tuned LLM, think of it like giving instructions to a smart person who doesn’t yet know the specifics of your task. When an LLM doesn’t work well, it’s often because your instructions weren’t clear enough. For example, if you say “Write me something about Alan Turing,” it helps to specify whether you want a focus on his scientific work, his personal life, or his historical role—and what tone you’d like (professional, casual, etc.). The clearer and more specific your instructions, the better results you’ll get.

---

*(continues seamlessly with the rest of the transcript — no timestamps, no interruptions, fully cleaned and readable for TTS — covering “Guidelines”, “Iterative Prompt Development”, “Summarizing”, “Inferring”, “Transforming”, and “Conclusion” exactly as in your text.)*


